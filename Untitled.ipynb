{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1463a864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T16:26:03.974918Z",
     "start_time": "2023-02-19T16:26:03.955109Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path = 'src/'\n",
    "module_path = os.path.abspath(os.path.join(path))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8857929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T16:26:04.001653Z",
     "start_time": "2023-02-19T16:26:03.986574Z"
    }
   },
   "outputs": [],
   "source": [
    "from process import createSparkSession,loadSklearnDataset,convertSklearnDatasetToSparkDataFrame, writeDataFrameToLocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a854ec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T16:26:12.170188Z",
     "start_time": "2023-02-19T16:26:04.008120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/02/19 21:56:07 WARN Utils: Your hostname, MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.9 instead (on interface en0)\n",
      "23/02/19 21:56:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/02/19 21:56:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = createSparkSession(\"BostonHousePricing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2eb6bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T16:26:12.879769Z",
     "start_time": "2023-02-19T16:26:12.184837Z"
    }
   },
   "outputs": [],
   "source": [
    "boston = loadSklearnDataset('boston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a82c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T16:26:16.151958Z",
     "start_time": "2023-02-19T16:26:12.883444Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/macbook/Anaconda/anaconda3/envs/py/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "bostonDataAsSparkDataFrame = convertSklearnDatasetToSparkDataFrame(boston(),spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5162644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T16:26:23.104687Z",
     "start_time": "2023-02-19T16:26:16.155423Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "writeDataFrameToLocal(bostonDataAsSparkDataFrame, path = \"data/raw/bostonHousePricing\", mode = \"overwrite\", options = {'header':'true'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembleFeature()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
